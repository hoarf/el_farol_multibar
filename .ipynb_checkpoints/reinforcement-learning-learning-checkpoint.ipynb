{
 "metadata": {
  "name": "",
  "signature": "sha256:923f0f22192af17cbb3e7ab3a65846aa4d10436e25d8870da61c43ae19e16e46"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from matplotlib import pyplot as plt\n",
      "%pprint"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Pretty printing has been turned OFF\n"
       ]
      }
     ],
     "prompt_number": 460
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Notation"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "'The Book': This refers to the book: Russell, Stuart, and Peter Norvig. \"Artificial intelligence: a modern approach.\" (1995).\n",
      "\n",
      "State: State here is read as the index of a matrix. For instance in the Q matrix the position Q[0,1] corresponds to all the Q-values associated wit the state (0,1) for any given action. **Note that all the index here are 0-based as opposed to 1-based index in the book**\n",
      "\n",
      "Action: This is one of the five possible choices for the agent at any given state, namely: LEFT, TOP, RIGHT, BOTTOM, STAND_STILL, that will be represented in the algorith by the index 0,1,2,3,4 respectivelly"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Reads the evironment data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "rewards_data = pd.read_csv('/vagrant_data/src/reinforcement-learning-practice/rewards.csv', index_col=[0,1])\n",
      "action_frequency_data = pd.read_csv('/vagrant_data/src/reinforcement-learning-practice/state_action_frequency.csv', index_col=[0,1,2])\n",
      "\n",
      "print rewards_data\n",
      "print action_frequency_data.frequency"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "                           reward\n",
        "state-index0 state-index1        \n",
        "0            0            -0.0380\n",
        "             1             0.0886\n",
        "             2             0.2152\n",
        "             3             1.0000\n",
        "1            0            -0.1646\n",
        "             1                NaN\n",
        "             2            -0.4430\n",
        "             3            -1.0000\n",
        "2            0            -0.2911\n",
        "             1            -0.4177\n",
        "             2            -0.5443\n",
        "             3            -0.7722\n",
        "state-index0  state-index1  action\n",
        "0             0             0        -9999\n",
        "                            1            0\n",
        "                            2            0\n",
        "                            3        -9999\n",
        "                            4        -9999\n",
        "              1             0            0\n",
        "                            1        -9999\n",
        "                            2            0\n",
        "                            3        -9999\n",
        "                            4        -9999\n",
        "              2             0            0\n",
        "                            1            0\n",
        "                            2            0\n",
        "                            3        -9999\n",
        "                            4        -9999\n",
        "              3             0            0\n",
        "                            1            0\n",
        "                            0        -9999\n",
        "                            0        -9999\n",
        "                            4        -9999\n",
        "1             0             0        -9999\n",
        "                            1            0\n",
        "                            2        -9999\n",
        "                            3            0\n",
        "                            4        -9999\n",
        "              1             0        -9999\n",
        "                            1        -9999\n",
        "                            2        -9999\n",
        "                            3        -9999\n",
        "                            4        -9999\n",
        "              2             0        -9999\n",
        "                            1            0\n",
        "                            2            0\n",
        "                            3            0\n",
        "                            4        -9999\n",
        "              3             0        -9999\n",
        "                            1        -9999\n",
        "                            2        -9999\n",
        "                            3        -9999\n",
        "                            4            0\n",
        "2             0             0        -9999\n",
        "                            1        -9999\n",
        "                            2            0\n",
        "                            3            0\n",
        "                            4        -9999\n",
        "              1             0            0\n",
        "                            1        -9999\n",
        "                            2            0\n",
        "                            3        -9999\n",
        "                            4        -9999\n",
        "              2             0            0\n",
        "                            1        -9999\n",
        "                            2            0\n",
        "                            3            0\n",
        "                            4        -9999\n",
        "              3             0        -9999\n",
        "                            1        -9999\n",
        "                            2        -9999\n",
        "                            3        -9999\n",
        "                            4            0\n",
        "Name: frequency, Length: 60, dtype: float64\n"
       ]
      }
     ],
     "prompt_number": 728
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Converts the data into a more mathy format\n",
      "\n",
      "This enables the handling of a state as the index of a matrix, I.E rewards[1,0] corresponds to the reward associated with the state (1,0) which is convenient and makes the syntax more like the one in the book"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "rewards = rewards_data.as_matrix().reshape((3,4))\n",
      "action_frequency = action_frequency_data.as_matrix().reshape((3,4,5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 729
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Model parameters"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is constant, a percept represents an environment stimulus\n",
      "START_PERCEPT = {\n",
      "  'state': (0,0),\n",
      "  'reward': rewards[0,0],\n",
      "  'terminal': False\n",
      "}\n",
      "\n",
      "# Optimistic reward estimation\n",
      "R_PLUS = 2\n",
      "\n",
      "# At least how many times each state should be tried\n",
      "N_E = 5\n",
      "\n",
      "# Learning rate\n",
      "alpha = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 730
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Initializations"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# A table containing the action-value pairs\n",
      "# Domain is State-index0 x State-index1 x Action\n",
      "Q = action_frequency\n",
      "\n",
      "# A table containing the state-action pairs\n",
      "# Domain is State-index0 x State-index1 x Action\n",
      "N = np.zeros((3,4,5))\n",
      "\n",
      "# Last action taken\n",
      "a = None\n",
      "\n",
      "# Previous state\n",
      "i = None\n",
      "\n",
      "# Previous state's reward\n",
      "r = None\n",
      "\n",
      "# 'SOMETHING SOMETHING MADNESS SOMETHING SOMETHING DIFFERENT RESULTS' - Einstein\n",
      "np.random.seed = 10"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 731
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# The main thing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# This is the main algorithm that decides the new action for the agent for a given percept\n",
      "def Q_learn_agent(percept):\n",
      "    global i, a, r, Q, N\n",
      "    j = percept['state']\n",
      "    if i:\n",
      "        N[i][a] += 1\n",
      "        Q[i][a] = Q[i][a] + alpha*(r + np.max(Q[j]) - Q[i][a])\n",
      "    if percept['terminal']:\n",
      "        i = None\n",
      "    else:\n",
      "        i = j\n",
      "        r = percept['reward']\n",
      "    a = choose_action(j)\n",
      "    return a\n",
      "\n",
      "# The exploratory function written in the literature, it decides wheter or not we already explored enough and are ready to be greedy\n",
      "def exploratory_fuction(u, n):\n",
      "    return R_PLUS if n < N_E else u\n",
      "\n",
      "# This makes our exploratry_function accept vectors as argument instead of scalars\n",
      "v_exploratory_function = np.vectorize(exploratory_fuction)\n",
      "\n",
      "# At state: 'j' choses something to do.\n",
      "def choose_action(j):\n",
      "    utility = v_exploratory_function(Q[j],N[j])\n",
      "    return np.unravel_index(np.argmax(utility),utility.shape)\n",
      "\n",
      "# This is the environment deciding what feedback to give to the agent\n",
      "# range(0,5) is action domain, i.e [0, 1, .. , 4]\n",
      "# 1: is the number of choices it needs to produce; the choices are uniformelly distributed\n",
      "def new_percept(new_action):\n",
      "    # new_action = np.random.choice(range(0,5),1,p=action_frequency[i])\n",
      "    new_state = calculate_new_state_based_on_action(i, new_action)\n",
      "    return {\n",
      "      'state': new_state,\n",
      "      'reward': rewards[new_state],\n",
      "      'terminal': new_state == (1,3) or new_state == (2,3)\n",
      "    }\n",
      "\n",
      "action_to_symbol_map = {\n",
      "    0: '<-',\n",
      "    1: '^',\n",
      "    2: '->',\n",
      "    3: 'v',\n",
      "    4: '-'\n",
      "}\n",
      "\n",
      "# This calculates the coordinates of the new state based on the previous state plus the action\n",
      "# Action LEFT=0 ; TOP=1; RIGHT=2; BOTTOM=3; STANT_STILL=4;\n",
      "def calculate_new_state_based_on_action(state, action):\n",
      "    state = (state[0]  , state[1]-1) if action == 0 else state\n",
      "    state = (state[0]+1, state[1]  ) if action == 1 else state    \n",
      "    state = (state[0]  , state[1]+1) if action == 2 else state\n",
      "    state = (state[0]-1, state[1]  ) if action == 3 else state\n",
      "    return state\n",
      "\n",
      "# this is where the whole process start\n",
      "start_state_utility = []\n",
      "def learn(nepochs=300):\n",
      "    global start_state_utility\n",
      "    for epoch in xrange(1,nepochs):\n",
      "       current_percept = START_PERCEPT\n",
      "       start_state_utility.append(Q[0,0])\n",
      "       while True:\n",
      "           new_action = Q_learn_agent(current_percept)\n",
      "           if not i: # means we reached a terminal state, let's start over a new epoch\n",
      "                break\n",
      "           np = new_percept(new_action)\n",
      "           current_percept = np\n",
      "    print(\"Done.\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 732
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q\n",
      "N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 736,
       "text": [
        "array([[[ 8595.,  8595.,  8594.,  8594.,  8593.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.]],\n",
        "\n",
        "       [[    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.]],\n",
        "\n",
        "       [[    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.]]])"
       ]
      }
     ],
     "prompt_number": 736
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "nepoch = 2\n",
      "learn(nepoch)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-734-79706b93f741>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;32m<ipython-input-732-790377e0c167>\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(nepochs)\u001b[0m\n\u001b[0;32m     55\u001b[0m        \u001b[0mstart_state_utility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m        \u001b[1;32mwhile\u001b[0m \u001b[0mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m            \u001b[0mnew_action\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mQ_learn_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcurrent_percept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# means we reached a terminal state, let's start over a new epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-732-790377e0c167>\u001b[0m in \u001b[0;36mQ_learn_agent\u001b[1;34m(percept)\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpercept\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'reward'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-732-790377e0c167>\u001b[0m in \u001b[0;36mchoose_action\u001b[1;34m(j)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# At state: 'j' choses something to do.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mchoose_action\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mutility\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mv_exploratory_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mutility\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1688\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1689\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/numpy/lib/function_base.pyc\u001b[0m in \u001b[0;36m_vectorize_call\u001b[1;34m(self, func, args)\u001b[0m\n\u001b[0;32m   1755\u001b[0m                       for _a in args]\n\u001b[0;32m   1756\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1757\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1758\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1759\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m<ipython-input-732-790377e0c167>\u001b[0m in \u001b[0;36mexploratory_fuction\u001b[1;34m(u, n)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;31m# The exploratory function written in the literature, it decides wheter or not we already explored enough and are ready to be greedy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexploratory_fuction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mR_PLUS\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mN_E\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# This makes our exploratry_function accept vectors as argument instead of scalars\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 734
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print Q[0,0]\n",
      "print Q[0,1]\n",
      "print Q[0,2]\n",
      "print Q[0,3]\n",
      "print Q[1,0]\n",
      "print Q[1,1]\n",
      "print Q[1,2]\n",
      "print Q[1,3]\n",
      "print Q[2,0]\n",
      "print Q[2,1]\n",
      "print Q[2,2]\n",
      "print Q[2,3]\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[-0.038  0.     0.     0.     0.   ]\n",
        "[ 886.    0.    0.    0.    0.]\n",
        "[ 0.2152  0.      0.      0.      0.    ]\n",
        "[ 2.4304  0.      0.      0.      0.    ]\n",
        "[ 0.  0.  0.  0.  0.]\n",
        "[ 0.  0.  0.  0.  0.]\n",
        "[-0.443  0.     0.     0.     0.   ]\n",
        "[ 0.  0.  0.  0.  0.]\n",
        "[ 0.  0.  0.  0.  0.]\n",
        "[ 0.  0.  0.  0.  0.]\n",
        "[-0.5443  0.      0.      0.      0.    ]\n",
        "[ 0.  0.  0.  0.  0.]\n"
       ]
      }
     ],
     "prompt_number": 697
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Results"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Utility of start state (0,0) over the epochs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plt.plot(xrange(1,nepoch), start_state_utility, label=range(0,5))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 683,
       "text": [
        "[<matplotlib.lines.Line2D object at 0x7f47080fc350>, <matplotlib.lines.Line2D object at 0x7f47080fc6d0>, <matplotlib.lines.Line2D object at 0x7f470814a690>, <matplotlib.lines.Line2D object at 0x7f470814a450>, <matplotlib.lines.Line2D object at 0x7f4707fa9210>]"
       ]
      },
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEACAYAAABRQBpkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3Ih9AQAAAAAAAAAAAAAAAMDx9P8TBtmUX87e4gAAAABJRU5ErkJggg==\n",
       "text": [
        "<matplotlib.figure.Figure object at 0x7f47080f4350>"
       ]
      }
     ],
     "prompt_number": 683
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 654,
       "text": [
        "array([[[  2.43565115e+03,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  2.04375031e+03,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  8.03043884e+02,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  1.70776605e+02,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00]],\n",
        "\n",
        "       [[  1.73145051e+03,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [ -4.29156250e-01,   1.72318072e+02,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00]],\n",
        "\n",
        "       [[ -2.82003125e-01,   7.92428543e+02,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [ -4.04646875e-01,   3.50339630e+02,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [ -5.27290625e-01,   1.11641579e+00,   1.41978973e+02,\n",
        "           0.00000000e+00,   0.00000000e+00],\n",
        "        [  0.00000000e+00,   0.00000000e+00,   0.00000000e+00,\n",
        "           0.00000000e+00,   0.00000000e+00]]])"
       ]
      }
     ],
     "prompt_number": 654
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "N"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 655,
       "text": [
        "array([[[ 1868.,     0.,     0.,     0.,     0.],\n",
        "        [ 1284.,     0.,     0.,     0.,     0.],\n",
        "        [  941.,     0.,     0.,     0.,     0.],\n",
        "        [  313.,     0.,     0.,     0.,     0.]],\n",
        "\n",
        "       [[ 1433.,     0.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.],\n",
        "        [    5.,   477.,     0.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.]],\n",
        "\n",
        "       [[    5.,  1072.,     0.,     0.,     0.],\n",
        "        [    5.,   719.,     0.,     0.,     0.],\n",
        "        [    5.,   459.,    53.,     0.,     0.],\n",
        "        [    0.,     0.,     0.,     0.,     0.]]])"
       ]
      }
     ],
     "prompt_number": 655
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q[:,:,4] # Utility for every state to go to bottom"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 656,
       "text": [
        "array([[ 0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.],\n",
        "       [ 0.,  0.,  0.,  0.]])"
       ]
      }
     ],
     "prompt_number": 656
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Q[0,0,:] # Utility for state (0,0) for every action"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 657,
       "text": [
        "array([ 2435.65114829,     0.        ,     0.        ,     0.        ,\n",
        "           0.        ])"
       ]
      }
     ],
     "prompt_number": 657
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 657
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 647
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}